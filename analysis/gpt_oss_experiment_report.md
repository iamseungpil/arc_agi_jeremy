# GPT-OSS 20B ARC-AGI Evaluation Report

GPT-OSS 20B 모델을 DreamCoder library primitives와 결합한 program synthesis 방식으로 ARC-AGI 평가 데이터셋 400문제를 해결하는 실험을 진행했다. 현재 246문제를 완료했으며 34문제를 정확히 해결해 13.8%의 정확도를 기록했다. 문제당 평균 707초(약 12분)가 소요되며, vLLM을 활용한 GPU 2,3 병렬 처리로 안정적인 추론 속도를 유지하고 있다.

## 모델 아키텍처

GPT-OSS 20B는 Mixture-of-Experts 구조를 채택한 오픈소스 언어 모델로, 활성 파라미터는 3.6B이다. 본 실험에서는 vLLM 서버를 통해 port 8001에서 모델을 서빙하며, Tensor Parallelism 2로 GPU 2개에 모델을 분산 배치했다. 컨텍스트 길이는 24,576 토큰으로 설정해 복잡한 ARC 문제의 다중 예제를 충분히 수용할 수 있다.

DreamCoder library는 538개의 사전 학습된 primitive 함수로 구성되며, 이전 문제 해결 과정에서 성공한 transform 함수를 primitive로 추가하는 방식으로 지속적으로 확장된다. 모델은 각 문제에 대해 5개의 초기 시도를 생성하고, 상위 3개 솔루션에 대해 각 2회의 수정을 시도하는 tree 구조로 작동한다. Prompt.REASONING 방식을 사용해 모델이 먼저 패턴을 분석한 후 Python transform 함수를 생성하도록 유도하며, 생성된 코드는 실행되어 최종 그리드 출력을 산출한다.

코드 생성 파이프라인은 LLM 응답에서 Python 백틱 블록을 추출하고, 샌드박스 환경에서 20초 타임아웃으로 실행한다. 실행 결과로 생성된 그리드와 정답을 비교해 정확도를 판정하며, 성공한 솔루션의 transform 함수는 library에 자동으로 추가된다. 이 과정은 완전히 비동기로 처리되며, asyncio.gather를 통해 병렬 처리 효율을 최대화한다.

## Primitive 선택 메커니즘

각 문제 해결 시 library의 모든 primitive를 현재 문제의 train 예제에 대해 평가한다. 평가 방식은 두 단계로 구성된다. Primary score는 해당 primitive가 완전히 정확하게 변환한 예제 개수를 세고, Secondary score는 예제별 셀 단위 정확도의 평균을 계산한다. 최종 점수는 Primary score와 Secondary score의 합으로 결정되며, 이를 softmax 함수로 변환해 확률 분포를 생성한 뒤 상위 k=2개 primitive를 확률적으로 샘플링한다. 선택된 2개 primitive는 프롬프트에 in-context 예제로 추가되며, 각 primitive가 실패한 예제에 대한 diff 정보도 함께 제공된다.

Library는 실험 진행 중 지속적으로 성장한다. 초기 538개 primitive로 시작했으며, 현재 251문제 완료 시점에서 789개로 증가했다. 각 문제 해결 후 정답 여부와 무관하게 해당 문제의 최상위 솔루션이 primitive로 추가되므로, 400문제 완료 시점에는 938개 primitive를 보유하게 된다. 문제 해결이 진행될수록 library가 확장되어 더 많은 참고 패턴을 활용할 수 있지만, 동시에 모든 primitive를 평가하는 계산 비용도 증가한다.

## 실험 결과

| 항목 | 값 |
|------|------|
| 진행률 | 248/400 (62.0%) |
| 정확도 | 34/248 (13.7%) |
| 평균 소요 시간 | 707초 (11.8분) |
| 정답 문제 | 34개 |
| 오답 문제 (총) | 214개 (86.3%) |
| ├─ 응답 생성 실패 | 111개 (44.8%) |
| └─ 잘못된 출력 | 103개 (41.5%) |
| 예상 완료 시간 | 약 30시간 |

실험은 2025년 10월 29일 시작되어 현재까지 안정적으로 진행 중이다. 13.7%의 정확도는 7% 정도였던 초기 버전 대비 개선된 수치지만, ARC-AGI의 고난이도를 고려하면 여전히 낮은 수준이다. 오답 214건 중 111건(44.8%)은 빈 솔루션으로 모델이 패턴을 파악하지 못하거나 코드 생성에 실패한 경우이며, 103건(41.5%)은 코드가 실행되었으나 잘못된 출력을 생성한 경우다. 응답 생성 실패가 절반 가까이를 차지하는 것은 ARC 문제의 추상적 패턴 인식이 현재 모델의 주요 한계임을 보여준다. 문제당 평균 12분이 소요되는 것은 5회 시도 + 6회 수정의 복잡한 tree 탐색 과정과 각 코드 실행의 오버헤드가 누적된 결과다. vLLM 서버는 평균 처리량 192 tokens/s (프롬프트), 116 tokens/s (생성)을 유지하며 GPU 메모리는 77GB/80GB로 안정적이다.

## 솔루션 사례 분석

140c817e 문제(정답)는 입력 그리드에서 값 1을 가진 셀을 찾아 해당 행과 열 전체를 1로 채우되, 교차점은 2로, 대각선 4방향은 3으로 설정하는 패턴이다. 모델은 이 규칙을 정확히 파악해 transform 함수를 생성했다. 첫 번째 솔루션은 모든 셀을 무조건 덮어쓰는 방식이고, 두 번째 솔루션은 값 0인 셀만 수정하는 조건부 방식이다. 두 솔루션 모두 정답을 산출했으며, 코드 품질 측면에서는 두 번째가 더 정교하다. 이 문제는 명확한 기하학적 패턴을 가지고 있어 모델이 예제에서 규칙을 추론하기 용이했다.

136b0064 문제(오답)는 복구 실험에서 솔루션 생성에 실패했다. 로그 파일이 비어있고 Python 코드 파일도 생성되지 않았으며, 프로세스가 중간에 종료되었다. 이는 LLM이 패턴을 파악하지 못하거나, 생성된 코드가 실행 중 타임아웃되었거나, 예외가 발생했을 가능성을 시사한다. 원본 실험 로그에서도 이 문제는 오답으로 기록되어 있어, 모델이 일관되게 해결하지 못하는 난이도가 높은 문제로 판단된다. 실패 원인을 정확히 파악하려면 전체 LLM 응답 로그와 실행 오류 메시지가 필요하다.
